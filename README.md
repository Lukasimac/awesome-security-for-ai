# Awesome Security Solutions for AI Systems [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of awesome solutions to hard AI security problems and risks.  This stands in contrast to using AI for security (for offense or defense) and is explicitly meant to link to software and solutions that help solve the problems

Other lists cover the many excellent frameworks, papers, attacks, safety, and so forth.  But new GenAI systems are subject to all new classes of attacks and it has been difficult to find projects and companies that solve these problems as they rarely shine through the noise of "ai security" as a phrase.

If you want to contribute, create a PR.

## Related awesome lists

* [ottosulin/awesome-ai-security](https://github.com/ottosulin/awesome-ai-security)
* [deepspaceharbor/awesome-ai-security](https://github.com/DeepSpaceHarbor/Awesome-AI-Security)
* [awesome-ai-for-cybersecurity](https://github.com/Billy1900/Awesome-AI-for-cybersecurity)
* [awesome-ai-safety](https://github.com/hari-sikchi/awesome-ai-safety)
* [awesome-llm-security](https://github.com/corca-ai/awesome-llm-security) - A curation of awesome tools, documents and projects about LLM Security.
* [awesome-ml-privacy-attacks](https://github.com/stratosphereips/awesome-ml-privacy-attacks) - An awesome list of papers on privacy attacks against machine learning.
* [awesome-ml-security](https://github.com/trailofbits/awesome-ml-security)

## Infographic

As an experiment, we'll try to keep an [infographic of awesome ai security solutions](awesome-ai-security-infographic.svg) up-to-date as an open source SVG file. This will be a fast visual overview with a mix of logos and text.

<a xlink:href="http://localhost" xlink:title="">

## Solution Categories

* [Confidential Computing](#confidential-computing)
* [Encryption](#encryption)
* [Governance](#governance)
* [Model Protection](#model-protection)
* [Prompt Firewall](#prompt-firewall)
* [QA](#qa)
* [Training Protection](#training-protection)
* [Contributing](#contributing)

------

## Confidential Computing

* Fortanix
* Opaque Systems - Confidential compute models

## Encryption

* [IronCore Labs' Cloaked AI](https://ironcorelabs.com/products/cloaked-ai/)

## Governance


## Model Protection

* Robust Intelligence
* Protect AI
* HiddenLayer
  * Protects models from inversion
  * New 2024-03-21: have prompt firewall
* Cranium
* Adversa
* Advai
* Mindgard AI
* LLM Guard
* CredoAI

## Prompt Firewall

* CalypsoAI
* Robust Intelligence
* HiddenLayer
* AIShield
* RebuffAI
* Lakera AI
* TripleBlind ??
* Prompt Security


## QA

* Freeplay AI
* Patronus AI (is this the right category?)
* Arthur

## Training Protection

* Mostly AI
* Synthesis AI
* Assembly AI
* Private-AI
* Protopia AI
* DynamoFL
* CalypsoAI - Audits sensitive data and prevents data from getting into outside AI models.


------

## Contributing

Contributions are welcome.  Add new items, suggest changes to categories or descriptions, etc. We're not aiming to be comprehensive, but to provide a short list of the most notable solutions in each category.

That said, there are some rules as there is an established format and approach. Please carefully read the [guidelines for contributing in the `contributing.md`](./contributing.md) file in this repo.

